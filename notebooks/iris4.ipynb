{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "#sns.set_palette(\"Set1\")\n",
    "#sns.set_style(\"whitegrid\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Section 1) Before neural networks: Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 The iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = sns.load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_species = list(set(iris.species))\n",
    "print(list_of_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = sns.pairplot(iris, hue=\"species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_histogram(my_species,feature,n_bins=20,normed=None,data=iris):\n",
    "    \"\"\"Plot a histogram of the given feature according to a given species.\"\"\"\n",
    "    mask = data['species']==my_species\n",
    "    hist0 = data[feature][~mask]\n",
    "    hist1 = data[feature][mask]\n",
    "    histograms = [hist0,hist1]\n",
    "    labels = ['not '+my_species, my_species]\n",
    "    fig,ax = plt.subplots(figsize=(12,5))\n",
    "    plt.hist(histograms, histtype='bar',bins=n_bins,normed=normed,label=labels);\n",
    "    plt.title(my_species,fontsize='xx-large')\n",
    "    plt.xlabel(feature,fontsize='x-large')\n",
    "    plt.legend(fontsize='x-large')\n",
    "    ax.tick_params(labelsize='large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram('setosa','petal_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_histogram('setosa','petal_width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram('virginica','petal_width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem we want to address: knowing the petal width, predict if the iris is a virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Logistic regression with sklearn: guessing virginica knowing the petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = iris['petal_width'].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = iris.species.apply(lambda x: 1 if x=='virginica' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "import sklearn.linear_model\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "sklearn.model_selection.train_test_split(x,y,test_size = 0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_sklearn = sklearn.linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_sklearn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_histogram('virginica','petal_width',normed=True)\n",
    "petal_widths = np.arange(0,3,0.01)\n",
    "predicted_proba = model_sklearn.predict_proba(petal_widths.reshape(-1,1))[:,1]\n",
    "plt.plot(petal_widths,predicted_proba,'r--',label='predicted proba')\n",
    "plt.plot([0,3],[.5,.5],'k--',linewidth=1)\n",
    "plt.legend(fontsize='x-large')\n",
    "plt.yticks([0,0.5,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_train = model_sklearn.score(x_train,y_train)\n",
    "print(accuracy_train)\n",
    "# normally the score should be 0.958333 = 115/120\n",
    "# knowing that there are 5 misclassified, on a total of 120=x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_test = model_sklearn.score(x_test,y_test)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import regularizers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_keras = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer0 = Dense(1,input_dim=1,kernel_regularizer=regularizers.l2(.1))\n",
    "model_keras.add(layer0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1 = Activation('sigmoid')\n",
    "model_keras.add(layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_keras.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_keras(reg = .1):\n",
    "    model_keras = Sequential()\n",
    "    layer0 = Dense(1,input_dim=1,kernel_regularizer=regularizers.l2(reg))\n",
    "    model_keras.add(layer0)\n",
    "    layer1 = Activation('sigmoid')\n",
    "    model_keras.add(layer1)\n",
    "    sgd = optimizers.SGD(lr=0.05)\n",
    "    model_keras.compile(optimizer=sgd, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_keras.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_keras.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_keras.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_keras.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WITH REGULARIZATION = .1 THE PROBAS CURVE IS MUCH FLATTER (HOWEVER EPOCHS LARGE IS)THAN WITH SKLEARN\n",
    "\n",
    "ONE NEEDS REG = .01 AND 5000 EPOCHS TO GET THE SAME CURVE AS WITH SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_keras = initialize_keras(reg=.01)\n",
    "plot_histogram('virginica','petal_width',normed=True)\n",
    "petal_widths = np.arange(0,3,0.01)\n",
    "model_keras.fit(x_train,y_train,epochs=500,verbose=0)\n",
    "predicted_proba = model_keras.predict(petal_widths.reshape(-1,1))[:,0]\n",
    "plt.plot(petal_widths,predicted_proba,'r--',label='proba')\n",
    "plt.plot([0,3],[.5,.5],'k--',linewidth=1)\n",
    "plt.legend()\n",
    "plt.yticks([0,0.5,1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the logistic regression algorithm does the following: try to find a function \n",
    "$$ P_{normal} : [0,100] \\to [0,1]$$\n",
    "such that for a random value of a coordinate $x \\in [0,100]$,   \n",
    "\n",
    "$ P_{normal}(x)$ is an estimate (= a guess) of the probability that the traffic is slow.\n",
    "\n",
    "The idea of logistic regression is to look for a function of the form:\n",
    "$$ P_{normal}(x) = \\sigma(wx+b)$$\n",
    "where \n",
    "$$\\sigma : \\mathbb{R} \\to [0,1]$$ is the **sigmoid function ** defined by \n",
    "$$ \\sigma(x) = \\frac{1}{1+e^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_sigmoid = np.arange(-10,10,0.01)\n",
    "y_sigmoid = sigmoid(x_sigmoid)\n",
    "_ = plt.plot(x_sigmoid,y_sigmoid)\n",
    "plt.plot([-10,10],[0.5,0.5],'k-',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "plt.subplot(121)\n",
    "x_sigmoid = np.arange(-20,20,0.01)\n",
    "y_sigmoid = sigmoid(x_sigmoid)\n",
    "_ = plt.plot(x_sigmoid,y_sigmoid)\n",
    "plt.title('Sigmoid')\n",
    "plt.subplot(122)\n",
    "w = -1\n",
    "b = 7\n",
    "y_shifted = sigmoid(w*x_sigmoid + b)\n",
    "_ = plt.plot(x_sigmoid,y_shifted)\n",
    "plt.title('Shifted sigmoid')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajouter graphe du reseau neronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Section 2) Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization, gradient descent with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1,input_dim=1,kernel_regularizer=regularizers.l2(.1)))\n",
    "model.add(Activation('sigmoid'))\n",
    "sgd = optimizers.SGD(lr=0.05)\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_meshgrid(xstart,xend,xstep,ystart,yend,ystep):\n",
    "    xx,yy = np.mgrid[xstart:xend:xstep,ystart:yend:ystep]\n",
    "    return xx,yy\n",
    "x_grid, y_grid = get_meshgrid(-10,10,.1,-10,10,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(model,weight,bias,x,y,C=1.):\n",
    "    \"\"\"Compute the accuracy function.\"\"\"\n",
    "    layer =  model.layers[0]\n",
    "    layer.set_weights( [ np.array([[weight]]) , np.array([bias]) ] ) \n",
    "    accuracy = model.evaluate(x,y,verbose=0)[1]\n",
    "    return accuracy\n",
    "\n",
    "def get_accuracy1(weigth,bias):\n",
    "    return get_accuracy(model,weigth,bias,x_train,y_train,1.)\n",
    "\n",
    "vaccuracy = np.vectorize(get_accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes two minutes to run\n",
    "# acc_grid = vaccuracy(x_grid,y_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('../data/acc_grid', 'wb') as f:\n",
    "#     # Pickle the 'data' dictionary using the highest protocol available.\n",
    "#     pickle.dump(acc_grid, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../data/acc_grid', 'rb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    acc_grid =pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig,ax_acc = plt.subplots(figsize=(15,7))\n",
    "plt.pcolor(x_grid,y_grid,acc_grid,cmap='RdBu_r')\n",
    "plt.colorbar()\n",
    "plt.title('Accuracy',fontsize='xx-large')\n",
    "plt.xlabel('Weight (w)',fontsize='x-large')\n",
    "plt.ylabel('Bias (b)',fontsize='x-large')\n",
    "ax_acc.tick_params(labelsize='large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathcal{L}(p,y) = y \\log(p) + (1-y)\\log(1-p)$$\n",
    "$$\\mathcal{L} = \\sum_{i=1}^n y_i \\log(p_i) + (1-y_i)\\log(1-p_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp = np.arange(0,1,.01)\n",
    "loss1 = - np.log(pp)\n",
    "loss0 = -np.log(1-pp)\n",
    "plt.plot(pp,loss1,label='y = 1')\n",
    "plt.plot(pp,loss0,label='y = 0')\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Loss function (corss entropy)',fontsize='x-large')\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialise_keras_model(initial_weight = 9,initial_bias = 9,lr=0.05,reg=.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1,input_dim=1,kernel_regularizer=regularizers.l2(.1)))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    sgd = optimizers.SGD(lr=lr)\n",
    "    model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    layer =  model.layers[0]\n",
    "    layer.set_weights( [ np.array([[initial_weight]]) , np.array([initial_bias]) ] ) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loss(model,weight,bias,x,y,C=1.):\n",
    "    \"\"\"Compute the loss function.\"\"\"\n",
    "    layer =  model.layers[0]\n",
    "    layer.set_weights( [ np.array([[weight]]) , np.array([bias]) ] ) \n",
    "    loss = model.evaluate(x,y,verbose=0)[0]\n",
    "    return loss\n",
    "\n",
    "def get_loss1(weigth,bias):\n",
    "    return get_loss(model,weigth,bias,x_train,y_train,1.)\n",
    "\n",
    "vloss = np.vectorize(get_loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss_grid = vloss(x_grid,y_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('../data/loss_grid', 'wb') as f:\n",
    "#     # Pickle the 'data' dictionary using the highest protocol available.\n",
    "#     pickle.dump(loss_grid, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../data/loss_grid', 'rb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    loss_grid =pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig , ax_loss = plt.subplots(figsize=(20,10))\n",
    "plt.pcolor(x_grid , y_grid , loss_grid , norm=colors.LogNorm() , cmap='RdBu_r')\n",
    "plt.colorbar()\n",
    "plt.contour(x_grid, y_grid, loss_grid,20)\n",
    "plt.title('Loss function',fontsize='xx-large')\n",
    "plt.xlabel('weight',fontsize='x-large')\n",
    "plt.ylabel('bias',fontsize='x-large')\n",
    "\n",
    "model = initialise_keras_model(reg=.05)\n",
    "steps = 15\n",
    "for i in range(steps):\n",
    "    old_weight, old_bias = model.get_weights()[0][0][0], model.get_weights()[1][0]\n",
    "    model.fit(x_train,y_train,verbose=0,epochs = 8)\n",
    "    weight, bias = model.get_weights()[0][0][0], model.get_weights()[1][0]\n",
    "    plt.plot([old_weight,weight],[old_bias,bias],'kX--',markersize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Section 3) Neural Networks: when linear methods are not sufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_histogram('versicolor','petal_width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Goal: determine if an iris is a versicolor knowing its petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = iris.petal_width\n",
    "y = iris.species.apply(lambda x: 1 if x=='versicolor' else 0)\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "sklearn.model_selection.train_test_split(x,y,test_size = 0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_versicolor = Sequential()\n",
    "model_versicolor.add(Dense(1, input_dim=1 , kernel_regularizer=regularizers.l2(.1)))\n",
    "model_versicolor.add(Activation('sigmoid'))\n",
    "model_versicolor.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_versicolor.fit(x_train,y_train,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_histogram('versicolor','petal_width',normed=True)\n",
    "petal_widths = np.arange(0,3,0.01)\n",
    "probas = model_versicolor.predict(petal_widths.reshape(-1,1))[:,0]\n",
    "plt.plot(petal_widths,probas,'r--',label='proba')\n",
    "plt.plot([0,3],[.5,.5],'k--',linewidth=1,label = 'proba = 0.5')\n",
    "plt.legend()\n",
    "plt.yticks([0,0.5,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_versicolor = Sequential()\n",
    "model_versicolor.add(Dense(10, input_dim=1 ) )\n",
    "model_versicolor.add(Activation('sigmoid'))\n",
    "model_versicolor.add(Dense(1, input_dim=1 ) )\n",
    "model_versicolor.add(Activation('sigmoid'))\n",
    "sgd = optimizers.SGD(lr=0.05)\n",
    "model_versicolor.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_versicolor_model(lr = .05,h=5):\n",
    "    model_versicolor = Sequential()\n",
    "    model_versicolor.add(Dense(h, input_dim=1 ) )\n",
    "    model_versicolor.add(Activation('sigmoid'))\n",
    "    model_versicolor.add(Dense(1, input_dim=1 ) )\n",
    "    model_versicolor.add(Activation('sigmoid'))\n",
    "    sgd = optimizers.SGD(lr=lr)\n",
    "    model_versicolor.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model_versicolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_versicolor.fit(x_train,y_train,epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_versicolor = initialize_versicolor_model(lr = .1,h=5)\n",
    "n_rows = n_cols = 3\n",
    "fig = plt.subplots(n_rows,n_cols,figsize=(15,15),sharex=True,sharey=True)\n",
    "epochs=200\n",
    "petal_widths = np.arange(0,3,0.01)\n",
    "for i in range(1,n_rows**2+1):\n",
    "    plt.subplot(n_rows,n_cols, i)\n",
    "    model_versicolor.fit(x_train,y_train,epochs=epochs,verbose=0)\n",
    "    probas = model_versicolor.predict(petal_widths.reshape(-1,1))[:,0]\n",
    "    plt.plot(petal_widths,probas,label='after  {} epochs'.format(i*epochs))\n",
    "    plt.ylim((0,1))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_histogram('versicolor','petal_width',normed=True)\n",
    "probas = model_versicolor.predict(petal_widths.reshape(-1,1))[:,0]\n",
    "_=plt.plot(petal_widths,probas,'b',label='after  {} epochs'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellenious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction_train = logistic_classifier.predict_proba(x)\n",
    "# loss_train = sklearn.metrics.log_loss(y,prediction_train)\n",
    "# print(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print('coefficients:',model_sklearn.coef_ , model_sklearn.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_keras = initialize_keras()\n",
    "# num_steps = 20\n",
    "# epochs = 10\n",
    "# steps = range(num_steps)\n",
    "# loss = np.zeros(num_steps)\n",
    "# loss_test = np.zeros_like(loss)\n",
    "# for i in steps:\n",
    "#     model_keras.fit(x_train,y_train,epochs=epochs,verbose=0)\n",
    "#     loss[i] = model_keras.evaluate(x_train,y_train,verbose=0)[0]\n",
    "#     loss_test[i] = model_keras.evaluate(x_test,y_test,verbose=0)[0]\n",
    "    \n",
    "# plt.plot(steps,loss,label='train')\n",
    "# plt.plot(steps,loss_test,label='test')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#history = model.fit(x_train,y_train,epochs=10,verbose=0)\n",
    "# model.get_weights()\n",
    "# loss = model.evaluate(x_train,y_train,verbose=0)[0]\n",
    "# model.test_on_batch(x_train,y_train)\n",
    "# model.train_on_batch(x_train,y_train)\n",
    "# model.get_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
