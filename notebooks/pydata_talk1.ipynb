{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "#sns.set_palette(\"Set1\")\n",
    "#sns.set_style(\"whitegrid\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Section 1) Before neural networks: Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 The iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = sns.load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(iris, hue=\"species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_histogram(my_species,feature,n_bins=20,normed=None,data=iris):\n",
    "    \"\"\"Plot a histogram of the given feature according to a given species.\"\"\"\n",
    "    mask = data['species']==my_species\n",
    "    hist0 = data[feature][~mask]\n",
    "    hist1 = data[feature][mask]\n",
    "    histograms = [hist0,hist1]\n",
    "    labels = ['not '+my_species, my_species]\n",
    "    fig,ax = plt.subplots(figsize=(12,5))\n",
    "    plt.hist(histograms, histtype='bar',bins=n_bins,normed=normed,label=labels);\n",
    "    plt.title(my_species,fontsize='xx-large')\n",
    "    plt.xlabel(feature,fontsize='x-large')\n",
    "    plt.legend(fontsize='x-large')\n",
    "    ax.tick_params(labelsize='large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram('virginica','petal_width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem we want to address: knowing the petal width, predict if the iris is a virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Logistic regression with sklearn: guessing virginica knowing the petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = iris['petal_width'].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = iris.species.apply(lambda x: 1 if x=='virginica' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_sklearn = sklearn.linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sklearn.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram('virginica','petal_width',normed=True)\n",
    "petal_widths = np.arange(0,3,0.01)\n",
    "predicted_proba = model_sklearn.predict_proba(petal_widths.reshape(-1,1))[:,1]\n",
    "plt.plot(petal_widths,predicted_proba,'r--',label='predicted proba')\n",
    "plt.plot([0,3],[.5,.5],'k--',linewidth=1)\n",
    "plt.legend(fontsize='x-large')\n",
    "plt.yticks([0,0.5,1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of a model evaluated on the sample x,y is defined as \n",
    "\n",
    "$$ \\text{Accuracy} = \\frac{\\text{number of samples correctly classified}}{\\text{number of samples}}$$\n",
    "\n",
    "With keras, we can obtain the accuracy using the score method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sklearn.score(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import regularizers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_keras = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer0 = Dense(1,input_dim=1,kernel_regularizer=regularizers.l2(.1))\n",
    "model_keras.add(layer0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1 = Activation('sigmoid')\n",
    "model_keras.add(layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_keras.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_keras(reg = .1):\n",
    "    model_keras = Sequential()\n",
    "    layer0 = Dense(1,input_dim=1,kernel_regularizer=regularizers.l2(reg))\n",
    "    model_keras.add(layer0)\n",
    "    layer1 = Activation('sigmoid')\n",
    "    model_keras.add(layer1)\n",
    "    sgd = optimizers.SGD(lr=0.05)\n",
    "    model_keras.compile(optimizer=sgd, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_keras.fit(x,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras = initialize_keras(reg=.01)\n",
    "plot_histogram('virginica','petal_width',normed=True)\n",
    "petal_widths = np.arange(0,3,0.01)\n",
    "model_keras.fit(x,y,epochs=500,verbose=0)\n",
    "predicted_proba = model_keras.predict(petal_widths.reshape(-1,1))[:,0]\n",
    "plt.plot(petal_widths,predicted_proba,'r--',label='proba')\n",
    "plt.plot([0,3],[.5,.5],'k--',linewidth=1)\n",
    "plt.legend()\n",
    "plt.yticks([0,0.5,1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the logistic regression algorithm does the following: try to find a function \n",
    "$$ P: [0,3] \\to [0,1]$$\n",
    "such that for a random $x \\in [0,3]$ corresponding to a petal width, $P(x)$ is an estimate (= a guess) of the probability that the plant is a virginica.\n",
    "\n",
    "The idea of logistic regression is to look for a function of the form:\n",
    "$$P_{w,b}(x) = \\sigma(wx+b)$$\n",
    "where \n",
    "$$\\sigma : \\mathbb{R} \\to [0,1]$$ is the **sigmoid function ** defined by \n",
    "$$ \\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "We call $w$ the **weight** and $b$  the **bias**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sigmoid = np.arange(-10,10,0.01)\n",
    "y_sigmoid = sigmoid(x_sigmoid)\n",
    "plt.plot(x_sigmoid,y_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(221)\n",
    "w=1\n",
    "b=0\n",
    "y_shifted = sigmoid(w*x_sigmoid + b)\n",
    "plt.plot(x_sigmoid,y_shifted,label='w={}\\nb={}'.format(w,b))\n",
    "plt.legend(fontsize = 'xx-large')\n",
    "#plt.title('Shifted sigmoid')\n",
    "\n",
    "\n",
    "plt.subplot(222)\n",
    "w = -1\n",
    "b = 0\n",
    "y_shifted = sigmoid(w*x_sigmoid + b)\n",
    "plt.plot(x_sigmoid,y_shifted,label='w={}\\nb={}'.format(w,b))\n",
    "plt.legend(fontsize = 'xx-large')\n",
    "\n",
    "plt.subplot(223)\n",
    "w = 4\n",
    "b = 0\n",
    "y_shifted = sigmoid(w*x_sigmoid + b)\n",
    "plt.plot(x_sigmoid,y_shifted,label='w={}\\nb={}'.format(w,b))\n",
    "plt.legend(fontsize = 'xx-large')\n",
    "\n",
    "plt.subplot(224)\n",
    "w = -1\n",
    "b = 5\n",
    "y_shifted = sigmoid(w*x_sigmoid + b)\n",
    "plt.plot(x_sigmoid,y_shifted,label='w={}\\nb={}'.format(w,b))\n",
    "plt.legend(fontsize = 'xx-large')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajouter graphe du reseau neronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Section 2) Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization, gradient descent with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1,input_dim=1,kernel_regularizer=regularizers.l2(.1)))\n",
    "model.add(Activation('sigmoid'))\n",
    "sgd = optimizers.SGD(lr=0.05)\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_meshgrid(xstart,xend,xstep,ystart,yend,ystep):\n",
    "    xx,yy = np.mgrid[xstart:xend:xstep,ystart:yend:ystep]\n",
    "    return xx,yy\n",
    "x_grid, y_grid = get_meshgrid(-10,10,.1,-10,10,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(model,weight,bias,x,y,C=1.):\n",
    "    \"\"\"Compute the accuracy function.\"\"\"\n",
    "    layer =  model.layers[0]\n",
    "    layer.set_weights( [ np.array([[weight]]) , np.array([bias]) ] ) \n",
    "    accuracy = model.evaluate(x,y,verbose=0)[1]\n",
    "    return accuracy\n",
    "\n",
    "def get_accuracy1(weigth,bias):\n",
    "    return get_accuracy(model,weigth,bias,x,y,1.)\n",
    "\n",
    "vaccuracy = np.vectorize(get_accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes two minutes to run\n",
    "acc_grid = vaccuracy(x_grid,y_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('../data/acc_grid', 'wb') as f:\n",
    "#     # Pickle the 'data' dictionary using the highest protocol available.\n",
    "#     pickle.dump(acc_grid, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('../data/acc_grid', 'rb') as f:\n",
    "#     # Pickle the 'data' dictionary using the highest protocol available.\n",
    "#     acc_grid =pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax_acc = plt.subplots(figsize=(15,7))\n",
    "plt.pcolor(x_grid,y_grid,acc_grid,cmap='RdBu_r')\n",
    "plt.colorbar()\n",
    "plt.title('Accuracy',fontsize='xx-large')\n",
    "plt.xlabel('Weight (w)',fontsize='x-large')\n",
    "plt.ylabel('Bias (b)',fontsize='x-large')\n",
    "ax_acc.tick_params(labelsize='large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are so many zones where the accuracy are the same that it is impossible to find a method that would improve the weights step by step.\n",
    "\n",
    "To overcome this problem, we introduce a new metric: the cross entropy which we call our loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cross entropy  loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fix $w$ and $b$. We define \n",
    "$$\\mathcal{L}(p,y) = y \\log(p) + (1-y)\\log(1-p)$$\n",
    "$$\\mathcal{L_{w,b}} = \\sum_{i=1}^n y_i \\log(p_i) + (1-y_i)\\log(1-p_i)$$\n",
    "where $y_i\\in \\{0,1\\}$ is the actual classe of the i-th sample and $p_i \\in [0,1]$ is the probability $P_{w,b}(x_i)$ calculated by the logistic regression model for parameter values $w$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = np.arange(0,1,.01)\n",
    "loss1 = - np.log(pp)\n",
    "loss0 = -np.log(1-pp)\n",
    "plt.plot(pp,loss1,label='y = 1')\n",
    "plt.plot(pp,loss0,label='y = 0')\n",
    "plt.xlabel('p',fontsize='xx-large')\n",
    "plt.ylabel('Loss',fontsize='xx-large')\n",
    "plt.title('Loss function:  $\\mathcal{L}(p,y)$',fontsize='xx-large')\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialise_keras_model(initial_weight = 9,initial_bias = 9,lr=0.05,reg=.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1,input_dim=1,kernel_regularizer=regularizers.l2(.1)))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    sgd = optimizers.SGD(lr=lr)\n",
    "    model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    layer =  model.layers[0]\n",
    "    layer.set_weights( [ np.array([[initial_weight]]) , np.array([initial_bias]) ] ) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loss(model,weight,bias,x,y,C=1.):\n",
    "    \"\"\"Compute the loss function.\"\"\"\n",
    "    layer =  model.layers[0]\n",
    "    layer.set_weights( [ np.array([[weight]]) , np.array([bias]) ] ) \n",
    "    loss = model.evaluate(x,y,verbose=0)[0]\n",
    "    return loss\n",
    "\n",
    "def get_loss1(weigth,bias):\n",
    "    return get_loss(model,weigth,bias,x,y,1.)\n",
    "\n",
    "vloss = np.vectorize(get_loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_grid = vloss(x_grid,y_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('../data/loss_grid', 'wb') as f:\n",
    "#     # Pickle the 'data' dictionary using the highest protocol available.\n",
    "#     pickle.dump(loss_grid, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('../data/loss_grid', 'rb') as f:\n",
    "#     # Pickle the 'data' dictionary using the highest protocol available.\n",
    "#     loss_grid =pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , ax_loss = plt.subplots(figsize=(20,10))\n",
    "plt.pcolor(x_grid , y_grid , loss_grid , norm=colors.LogNorm() , cmap='RdBu_r')\n",
    "plt.colorbar()\n",
    "contour = plt.contour(x_grid, y_grid, loss_grid,20)\n",
    "plt.title('Loss function',fontsize='xx-large')\n",
    "plt.xlabel('weight',fontsize='x-large')\n",
    "plt.ylabel('bias',fontsize='x-large')\n",
    "\n",
    "model = initialise_keras_model(reg=.05)\n",
    "steps = 15\n",
    "for i in range(steps):\n",
    "    old_weight, old_bias = model.get_weights()[0][0][0], model.get_weights()[1][0]\n",
    "    model.fit(x,y,verbose=0,epochs = 8)\n",
    "    weight, bias = model.get_weights()[0][0][0], model.get_weights()[1][0]\n",
    "    plt.plot([old_weight,weight],[old_bias,bias],'kX--',markersize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Section 3) Neural Networks: when linear methods are not sufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram('versicolor','petal_width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Goal: determine if an iris is a versicolor knowing its petal width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First let's try using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = iris.petal_width\n",
    "y = iris.species.apply(lambda x: 1 if x=='versicolor' else 0)\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "sklearn.model_selection.train_test_split(x,y,test_size = 0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_versicolor = Sequential()\n",
    "model_versicolor.add(Dense(1, input_dim=1 , kernel_regularizer=regularizers.l2(.1)))\n",
    "model_versicolor.add(Activation('sigmoid'))\n",
    "model_versicolor.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_versicolor.fit(x_train,y_train,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram('versicolor','petal_width',normed=True)\n",
    "petal_widths = np.arange(0,3,0.01)\n",
    "probas = model_versicolor.predict(petal_widths.reshape(-1,1))[:,0]\n",
    "plt.plot(petal_widths,probas,'r--',label='proba')\n",
    "plt.plot([0,3],[.5,.5],'k--',linewidth=1,label = 'proba = 0.5')\n",
    "plt.legend()\n",
    "plt.yticks([0,0.5,1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's add a new layer to the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_versicolor_model(lr = .1,h=5):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(h, input_dim=1 ) )\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(1, input_dim=1 ) )\n",
    "    model.add(Activation('sigmoid'))\n",
    "    sgd = optimizers.SGD(lr=lr)\n",
    "    model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_versicolor = initialize_versicolor_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = n_cols = 3\n",
    "plt.subplots(n_rows,n_cols,figsize=(18,15),sharex=True,sharey=True)\n",
    "epochs=200\n",
    "petal_widths = np.arange(0,3,0.01)\n",
    "for i in range(1,n_rows**2+1):\n",
    "    plt.subplot(n_rows,n_cols, i)\n",
    "    model_versicolor.fit(x_train,y_train,epochs=epochs,verbose=0)\n",
    "    probas = model_versicolor.predict(petal_widths.reshape(-1,1))[:,0]\n",
    "    plt.plot(petal_widths,probas,label='after  {} epochs'.format(i*epochs))\n",
    "    plt.ylim((0,1))\n",
    "    plt.legend(fontsize='large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram('versicolor','petal_width',normed=True)\n",
    "probas = model_versicolor.predict(petal_widths.reshape(-1,1))[:,0]\n",
    "plt.plot(petal_widths,probas,'b',label='after  {} epochs'.format(i));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
